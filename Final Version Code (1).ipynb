{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bd3fced",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.0-0-g2d04fbe0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate transcripts:\n",
      "well|soar|wind|roll|deal|mist|left|gain|mass|time|scan|veil|area|will|bark|bake|rare|dead|axis|wrap|beam|post|long|head|beat|coat|seat|Mars|bird|walk|leaf|risk|side|like|role|spin|dash|pick|dull|loot|poor|call|link|doll|term|duck|wait|vain|easy|gasp|sell|rank|beef|monk|cave|fate|king|echo|rush|door|cafe|seal|skin|flex|ring|know|hide|dare|suit|cold|slab|blue|love|plum|duke|hook|fold|stab|crop|bean|lean|hope|flat|heel|pure|lift|tidy|even|clay|deep|zone|ally|site|rage|sour|nail\n",
      "Best candidate transcript:  plum\n",
      "Distance between the original gradient and the best candidate gradient using euclidean distance: 12337.656075086601\n",
      "Distance between the original gradient and the best candidate gradient using Manhattan distance: 29034.0\n",
      "Distance between the original gradient and the best candidate gradient using Minkowski distance: 228.41608381874252\n",
      "Levenshtein distance:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries that I need\n",
    "import librosa\n",
    "import numpy as np\n",
    "import deepspeech\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from scipy.spatial.distance import cityblock, cdist\n",
    "import enchant\n",
    "import textdistance\n",
    "\n",
    "# Load the tiny pre-trained model\n",
    "model = deepspeech.Model('deepspeech-0.9.3-models (2).pbmm')\n",
    "\n",
    "# Transcribe the audio file using DeepSpeech\n",
    "y, sr = librosa.load('./Wave Audio Files (Research)/Plum.wav', sr=16000, dtype=np.float64)\n",
    "transcript = model.stt((y * 32767).astype(np.int16))\n",
    "\n",
    "# Read the words from a text file and convert it to a set\n",
    "with open('words2.txt', 'r') as file:\n",
    "    word_list = set(file.read().split())\n",
    "\n",
    "# Define a dictionary that maps each character to its index in the original MFCCs array\n",
    "words = transcript.split()\n",
    "char_to_index = {char: j for i, word in enumerate(words) for j, char in enumerate(word)}\n",
    "\n",
    "# Generate candidate transcripts by comparing the length of each word to the lengths of words in the text file\n",
    "candidate_transcripts = []\n",
    "for word in words:\n",
    "    candidates = [candidate for candidate in word_list if abs(len(candidate) - len(word)) <= 1]\n",
    "    candidate_transcripts += candidates\n",
    "\n",
    "# Filter out candidate transcripts that are not equal in length to the original transcript\n",
    "candidate_transcripts = [candidate for candidate in candidate_transcripts if len(candidate) == len(transcript)]\n",
    "\n",
    "# Print the candidate transcripts\n",
    "print(\"Candidate transcripts:\")\n",
    "print(*candidate_transcripts, sep='|')\n",
    "\n",
    "# Compute the MFCCs of the audio file\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "# Compute the gradient of the audio file using the MFCCs\n",
    "gradient = np.gradient(mfccs, axis=1)\n",
    "\n",
    "# Normalize the gradient values to the range [0, 25]\n",
    "gradient = np.round(gradient / np.max(np.abs(gradient)) * 25)\n",
    "\n",
    "epsilon = 1e-8\n",
    "\n",
    "# Compute the gradients of the candidate transcripts\n",
    "candidate_gradients = []\n",
    "for candidate in candidate_transcripts:\n",
    "    candidate_mfccs = np.zeros((mfccs.shape[0], len(candidate)))\n",
    "    for i, char in enumerate(candidate):\n",
    "        # Map the character to an index in the MFCCs array, if it exists in the dictionary\n",
    "        if char in char_to_index:\n",
    "            candidate_mfccs[:, i] = mfccs[:, char_to_index[char]]\n",
    "    candidate_mfccs = np.hstack((candidate_mfccs, np.zeros((candidate_mfccs.shape[0], max(0, mfccs.shape[1] - candidate_mfccs.shape[1])))))\n",
    "    candidate_gradients.append(np.round(np.gradient(candidate_mfccs, axis=1) / (np.max(np.abs(candidate_mfccs)) + epsilon) * 25))\n",
    "\n",
    "\n",
    "# Store all the candidate transcripts and distances in a list of tuples\n",
    "candidates = []\n",
    "for i, candidate_gradient in enumerate(candidate_gradients):\n",
    "    # Compute the distances between the original gradient and the candidate gradient using different metrics\n",
    "    euclidean_distance = euclidean_distances(np.nan_to_num(gradient.T), np.nan_to_num(candidate_gradient.T)).sum()\n",
    "    manhattan_distance = cdist(gradient.T, candidate_gradient.T, 'cityblock').sum()\n",
    "    minkowski_distance = np.power(np.power(np.abs(gradient.T - candidate_gradient.T), 4).sum(axis=1), 1/4).sum()\n",
    "\n",
    "    # Compute the Levenshtein distance between the original transcript and the candidate transcript\n",
    "    lev_distance = textdistance.levenshtein.normalized_similarity(transcript, candidate_transcripts[i])\n",
    "\n",
    "    # Store the candidate transcript and distances in a tuple and add it to the list\n",
    "    candidate = (candidate_transcripts[i], euclidean_distance, manhattan_distance, minkowski_distance, lev_distance)\n",
    "    candidates.append(candidate)\n",
    "\n",
    "# Sort the list of candidates based on the Levenshtein distance (from smallest to largest)\n",
    "candidates = sorted(candidates, key=lambda x: x[4])\n",
    "\n",
    "# Find the best candidate transcript with the smallest Levenshtein distance closer to 1\n",
    "best_candidate_transcript = None\n",
    "best_lev_distance = 0\n",
    "for candidate in candidates:\n",
    "    transcript, euclidean_distance, manhattan_distance, minkowski_distance, lev_distance = candidate\n",
    "    if lev_distance > best_lev_distance:\n",
    "        best_candidate_transcript = transcript\n",
    "        best_lev_distance = lev_distance\n",
    "\n",
    "# Print the best candidate transcript and its distances\n",
    "print(\"Best candidate transcript: \",best_candidate_transcript)\n",
    "print(f\"Distance between the original gradient and the best candidate gradient using euclidean distance: {euclidean_distance}\")\n",
    "print(f\"Distance between the original gradient and the best candidate gradient using Manhattan distance: {manhattan_distance}\")\n",
    "print(f\"Distance between the original gradient and the best candidate gradient using Minkowski distance: {minkowski_distance}\")\n",
    "print(\"Levenshtein distance: \", best_lev_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23390c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TensorFlow: v2.3.0-6-g23ad988fcd\n",
      "DeepSpeech: v0.9.0-0-g2d04fbe0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidate transcripts:\n",
      "well|soar|wind|roll|deal|mist|left|gain|mass|time|scan|veil|area|will|bark|bake|rare|dead|axis|wrap|beam|post|long|head|beat|coat|seat|Mars|bird|walk|leaf|risk|side|like|role|spin|dash|pick|dull|loot|poor|call|link|doll|term|duck|wait|vain|easy|gasp|sell|rank|beef|monk|cave|fate|king|echo|rush|door|cafe|seal|skin|flex|ring|know|hide|dare|suit|cold|slab|blue|love|plum|duke|hook|fold|stab|crop|bean|lean|hope|flat|heel|pure|lift|tidy|even|clay|deep|zone|ally|site|rage|sour|nail\n",
      "Best candidate transcript:  bird\n",
      "Distance between the original gradient and the best candidate gradient using euclidean distance: 1343595.7281546034\n",
      "Distance between the original gradient and the best candidate gradient using Manhattan distance: 5856597.999998863\n",
      "Distance between the original gradient and the best candidate gradient using Minkowski distance: 14877.645910877163\n",
      "Levenshtein distance:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries that I need\n",
    "import librosa\n",
    "import numpy as np\n",
    "import deepspeech\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "from scipy.spatial.distance import cityblock, cdist\n",
    "import enchant\n",
    "import textdistance\n",
    "\n",
    "# Load the tiny pre-trained model\n",
    "model = deepspeech.Model('deepspeech-0.9.3-models (2).pbmm')\n",
    "\n",
    "# Transcribe the audio file using DeepSpeech\n",
    "y, sr = librosa.load('./Wave Audio Files (Research)/Bird.wav', sr=16000, dtype=np.float64)\n",
    "transcript = model.stt((y * 32767).astype(np.int16))\n",
    "\n",
    "# Read the words from a text file and convert it to a set\n",
    "with open('words2.txt', 'r') as file:\n",
    "    word_list = set(file.read().split())\n",
    "\n",
    "# Define a dictionary that maps each character to its index in the original MFCCs array\n",
    "words = transcript.split()\n",
    "char_to_index = {char: j for i, word in enumerate(words) for j, char in enumerate(word)}\n",
    "\n",
    "# Generate candidate transcripts by comparing the length of each word to the lengths of words in the text file\n",
    "candidate_transcripts = []\n",
    "for word in words:\n",
    "    candidates = [candidate for candidate in word_list if abs(len(candidate) - len(word)) <= 1]\n",
    "    candidate_transcripts += candidates\n",
    "\n",
    "# Filter out candidate transcripts that are not equal in length to the original transcript\n",
    "candidate_transcripts = [candidate for candidate in candidate_transcripts if len(candidate) == len(transcript)]\n",
    "\n",
    "# Print the candidate transcripts\n",
    "print(\"Candidate transcripts:\")\n",
    "print(*candidate_transcripts, sep='|')\n",
    "\n",
    "# Compute the MFCCs of the audio file\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr)\n",
    "\n",
    "epsilon = 1e-8\n",
    "    \n",
    "# Normalize the MFCCs to the range [0, 25]\n",
    "mfccs_normalized = np.round((mfccs - np.min(mfccs)) / (np.max(mfccs) - np.min(mfccs)) * 25)\n",
    "\n",
    "# Define the function to compute the gradient of the MFCCs with respect to the parameters\n",
    "def compute_gradient(params):\n",
    "    gradient = np.zeros_like(params)\n",
    "    gradient[:, 1:-1] = (params[:, 2:] - params[:, :-2]) / 2.0\n",
    "    gradient[:, 0] = params[:, 1] - params[:, 0]\n",
    "    gradient[:, -1] = params[:, -1] - params[:, -2]\n",
    "    return gradient\n",
    "\n",
    "# Initialize the gradient with zeros\n",
    "gradient = np.zeros_like(mfccs)\n",
    "\n",
    "# Define the learning rate for gradient descent\n",
    "learning_rate = 0.01\n",
    "\n",
    "# Perform gradient descent iterations\n",
    "for _ in range(1000):\n",
    "    # Compute the gradients of the candidate transcripts\n",
    "    candidate_gradients = []\n",
    "    for candidate in candidate_transcripts:\n",
    "        candidate_mfccs = np.zeros((mfccs.shape[0], len(candidate)))\n",
    "        for i, char in enumerate(candidate):\n",
    "            # Map the character to an index in the MFCCs array, if it exists in the dictionary\n",
    "            if char in char_to_index:\n",
    "                candidate_mfccs[:, i] = mfccs_normalized[:, char_to_index[char]]\n",
    "        candidate_mfccs = np.hstack((candidate_mfccs, np.zeros((candidate_mfccs.shape[0], max(0, mfccs.shape[1] - candidate_mfccs.shape[1])))))\n",
    "        candidate_gradients.append(np.round(compute_gradient(candidate_mfccs) / (np.max(np.abs(candidate_mfccs)) + epsilon) * 25))\n",
    "\n",
    "    # Update the gradient using gradient descent\n",
    "    for candidate_gradient in candidate_gradients:\n",
    "        gradient += learning_rate * candidate_gradient\n",
    "\n",
    "# Normalize the gradient values to the range [0, 25]\n",
    "gradient_normalized = np.round((gradient - np.min(gradient)) / (np.max(gradient) - np.min(gradient)) * 25)\n",
    "\n",
    "\n",
    "# Store all the candidate transcripts and distances in a list of tuples\n",
    "candidates = []\n",
    "for i, candidate_gradient in enumerate(candidate_gradients):\n",
    "    # Compute the distances between the original gradient and the candidate gradient using different metrics\n",
    "    euclidean_distance = euclidean_distances(np.nan_to_num(gradient.T), np.nan_to_num(candidate_gradient.T)).sum()\n",
    "    manhattan_distance = cdist(gradient.T, candidate_gradient.T, 'cityblock').sum()\n",
    "    minkowski_distance = np.power(np.power(np.abs(gradient.T - candidate_gradient.T), 4).sum(axis=1), 1/4).sum()\n",
    "\n",
    "    # Compute the Levenshtein distance between the original transcript and the candidate transcript\n",
    "    lev_distance = textdistance.levenshtein.normalized_similarity(transcript, candidate_transcripts[i])\n",
    "\n",
    "    # Store the candidate transcript and distances in a tuple and add it to the list\n",
    "    candidate = (candidate_transcripts[i], euclidean_distance, manhattan_distance, minkowski_distance, lev_distance)\n",
    "    candidates.append(candidate)\n",
    "\n",
    "# Sort the list of candidates based on the Levenshtein distance (from smallest to largest)\n",
    "candidates = sorted(candidates, key=lambda x: x[4])\n",
    "\n",
    "# Find the best candidate transcript with the smallest Levenshtein distance closer to 1\n",
    "best_candidate_transcript = None\n",
    "best_lev_distance = 0\n",
    "for candidate in candidates:\n",
    "    transcript, euclidean_distance, manhattan_distance, minkowski_distance, lev_distance = candidate\n",
    "    if lev_distance > best_lev_distance:\n",
    "        best_candidate_transcript = transcript\n",
    "        best_lev_distance = lev_distance\n",
    "\n",
    "# Print the best candidate transcript and its distances\n",
    "print(\"Best candidate transcript: \",best_candidate_transcript)\n",
    "print(f\"Distance between the original gradient and the best candidate gradient using euclidean distance: {euclidean_distance}\")\n",
    "print(f\"Distance between the original gradient and the best candidate gradient using Manhattan distance: {manhattan_distance}\")\n",
    "print(f\"Distance between the original gradient and the best candidate gradient using Minkowski distance: {minkowski_distance}\")\n",
    "print(\"Levenshtein distance: \", best_lev_distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dced36be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
